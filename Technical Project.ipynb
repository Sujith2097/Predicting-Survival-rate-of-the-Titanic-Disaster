{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PREDICTING THE SURVIVAL OF TITANIC DISASTER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importing neccessary libraries\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.ml import Pipeline\n",
    "from pyspark.sql.functions import mean,col,split, col, regexp_extract, when, lit\n",
    "from pyspark.ml.feature import StringIndexer\n",
    "from pyspark.ml.feature import VectorAssembler\n",
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
    "from pyspark.ml.feature import QuantileDiscretizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Starting the spark session\n",
    "* The spark session class is the entry point to all functionality in the spark.\n",
    "* Use sparksession.builder to create a basic spark session."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = SparkSession \\\n",
    "    .builder \\\n",
    "    .appName(\"Spark ML example on titanic data \") \\\n",
    "    .getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Loading the dataset from the given path\n",
    "s3_bucket_path = \"C:/users/Dell/DATA/train.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Giving a name for the dataframe as STD=Survival of titanic disaster\n",
    "STD_df = spark.read.csv(s3_bucket_path,header = 'True',inferSchema='True')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[PassengerId: int, Survived: int, Pclass: int, Name: string, Sex: string, Age: double, SibSp: int, Parch: int, Ticket: string, Fare: double, Cabin: string, Embarked: string]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Displaying the dataframe\n",
    "display(STD_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- PassengerId: integer (nullable = true)\n",
      " |-- Survived: integer (nullable = true)\n",
      " |-- Pclass: integer (nullable = true)\n",
      " |-- Name: string (nullable = true)\n",
      " |-- Sex: string (nullable = true)\n",
      " |-- Age: double (nullable = true)\n",
      " |-- SibSp: integer (nullable = true)\n",
      " |-- Parch: integer (nullable = true)\n",
      " |-- Ticket: string (nullable = true)\n",
      " |-- Fare: double (nullable = true)\n",
      " |-- Cabin: string (nullable = true)\n",
      " |-- Embarked: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Checking schema of the dataset\n",
    "STD_df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "891\n"
     ]
    }
   ],
   "source": [
    "#Displaying count of the passengers \n",
    "passengers_count = STD_df.count()\n",
    "print(passengers_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+--------+------+--------------------+------+----+-----+-----+----------------+-------+-----+--------+\n",
      "|PassengerId|Survived|Pclass|                Name|   Sex| Age|SibSp|Parch|          Ticket|   Fare|Cabin|Embarked|\n",
      "+-----------+--------+------+--------------------+------+----+-----+-----+----------------+-------+-----+--------+\n",
      "|          1|       0|     3|Braund, Mr. Owen ...|  male|22.0|    1|    0|       A/5 21171|   7.25| null|       S|\n",
      "|          2|       1|     1|Cumings, Mrs. Joh...|female|38.0|    1|    0|        PC 17599|71.2833|  C85|       C|\n",
      "|          3|       1|     3|Heikkinen, Miss. ...|female|26.0|    0|    0|STON/O2. 3101282|  7.925| null|       S|\n",
      "|          4|       1|     1|Futrelle, Mrs. Ja...|female|35.0|    1|    0|          113803|   53.1| C123|       S|\n",
      "|          5|       0|     3|Allen, Mr. Willia...|  male|35.0|    0|    0|          373450|   8.05| null|       S|\n",
      "+-----------+--------+------+--------------------+------+----+-----+-----+----------------+-------+-----+--------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "STD_df.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Now lets do some Exploratory Data Analysis\n",
    "* Knowing the survival rate of the passengers\n",
    "* Checking the survival rate using the sex feature\n",
    "* Checking the Survival rate using the passenger class feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+------+--------+\n",
      "|Survived|Pclass|Embarked|\n",
      "+--------+------+--------+\n",
      "|       0|     3|       S|\n",
      "|       1|     1|       C|\n",
      "|       1|     3|       S|\n",
      "|       1|     1|       S|\n",
      "|       0|     3|       S|\n",
      "+--------+------+--------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#selecting the features like Pclass and embarked \n",
    "STD_df.select(\"Survived\",\"Pclass\", \"Embarked\").show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+-----+\n",
      "|Survived|count|\n",
      "+--------+-----+\n",
      "|       1|  342|\n",
      "|       0|  549|\n",
      "+--------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Grouping the above selected features to know the survival rate accordingly\n",
    "STD_df.groupBy(\"Survived\").count().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[Survived: int, count: bigint]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "gropuBy_output = STD_df.groupBy(\"Survived\").count()\n",
    "display(gropuBy_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+--------+-----+\n",
      "|   Sex|Survived|count|\n",
      "+------+--------+-----+\n",
      "|  male|       0|  468|\n",
      "|female|       1|  233|\n",
      "|female|       0|   81|\n",
      "|  male|       1|  109|\n",
      "+------+--------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Displaying the count of survivors depending upon the Sex\n",
    "STD_df.groupBy(\"Sex\",\"Survived\").count().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+--------+-----+\n",
      "|Pclass|Survived|count|\n",
      "+------+--------+-----+\n",
      "|     1|       0|   80|\n",
      "|     3|       1|  119|\n",
      "|     1|       1|  136|\n",
      "|     2|       1|   87|\n",
      "|     2|       0|   97|\n",
      "|     3|       0|  372|\n",
      "+------+--------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Displaying the count of survivors depending upon the passengers class\n",
    "STD_df.groupBy(\"Pclass\",\"Survived\").count().show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Cleaning and Preprocessing \n",
    "* To deal with the null values an extensive data cleaning is done by finding the mean values for the age.\n",
    "* Mean of the age is identified by the intials before the names of the passengers.\n",
    "* Inorder to proceed further we need to first replace the misspelled intials"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This function is used to print feature with null values and null count \n",
    "def null_value_count(df):\n",
    "  null_columns_counts = []\n",
    "  numRows = df.count()\n",
    "  for k in df.columns:\n",
    "    nullRows = df.where(col(k).isNull()).count()\n",
    "    if(nullRows > 0):\n",
    "      temp = k,nullRows\n",
    "      null_columns_counts.append(temp)\n",
    "  return(null_columns_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------------+-----------------+\n",
      "|Column_With_Null_Value|Null_Values_Count|\n",
      "+----------------------+-----------------+\n",
      "|                   Age|              177|\n",
      "|                 Cabin|              687|\n",
      "|              Embarked|                2|\n",
      "+----------------------+-----------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Calling function\n",
    "null_columns_count_list = null_value_count(STD_df)\n",
    "#Displaying the Null values count from columns containing null values \n",
    "spark.createDataFrame(null_columns_count_list, ['Column_With_Null_Value', 'Null_Values_Count']).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* To replace these NaN values, we can assign them the mean age of the dataset.But the problem is, there were many people with many different ages.We just cant assign a 4 year kid with the mean age that is 29 years\n",
    "* We should search the Feature Description. Looking at the function, we can see that the names have a titles like Mr or Mrs. So we can allocate to the respective groups the mean values of Mr and Mrs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "29.69911764705882\n"
     ]
    }
   ],
   "source": [
    "#Calculating the mean age to handle the null values in the age feature\n",
    "mean_age = STD_df.select(mean('Age')).collect()[0][0]\n",
    "print(mean_age)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+\n",
      "|                Name|\n",
      "+--------------------+\n",
      "|Braund, Mr. Owen ...|\n",
      "|Cumings, Mrs. Joh...|\n",
      "|Heikkinen, Miss. ...|\n",
      "|Futrelle, Mrs. Ja...|\n",
      "|Allen, Mr. Willia...|\n",
      "+--------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "STD_df.select(\"Name\").show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using the Regex \"\"[A-Za-z]+).\" we extract the initials from the Name. It looks for strings which lie between A-Z or a-z and followed by a .(dot)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+--------+------+--------------------+------+----+-----+-----+----------------+-------+-----+--------+-------+\n",
      "|PassengerId|Survived|Pclass|                Name|   Sex| Age|SibSp|Parch|          Ticket|   Fare|Cabin|Embarked|Initial|\n",
      "+-----------+--------+------+--------------------+------+----+-----+-----+----------------+-------+-----+--------+-------+\n",
      "|          1|       0|     3|Braund, Mr. Owen ...|  male|22.0|    1|    0|       A/5 21171|   7.25| null|       S|     Mr|\n",
      "|          2|       1|     1|Cumings, Mrs. Joh...|female|38.0|    1|    0|        PC 17599|71.2833|  C85|       C|    Mrs|\n",
      "|          3|       1|     3|Heikkinen, Miss. ...|female|26.0|    0|    0|STON/O2. 3101282|  7.925| null|       S|   Miss|\n",
      "|          4|       1|     1|Futrelle, Mrs. Ja...|female|35.0|    1|    0|          113803|   53.1| C123|       S|    Mrs|\n",
      "|          5|       0|     3|Allen, Mr. Willia...|  male|35.0|    0|    0|          373450|   8.05| null|       S|     Mr|\n",
      "+-----------+--------+------+--------------------+------+----+-----+-----+----------------+-------+-----+--------+-------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "STD_df = STD_df.withColumn(\"Initial\",regexp_extract(col(\"Name\"),\"([A-Za-z]+)\\.\",1))\n",
    "STD_df.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+\n",
      "| Initial|\n",
      "+--------+\n",
      "|     Don|\n",
      "|    Miss|\n",
      "|Countess|\n",
      "|     Col|\n",
      "|     Rev|\n",
      "|    Lady|\n",
      "|  Master|\n",
      "|     Mme|\n",
      "|    Capt|\n",
      "|      Mr|\n",
      "|      Dr|\n",
      "|     Mrs|\n",
      "|     Sir|\n",
      "|Jonkheer|\n",
      "|    Mlle|\n",
      "|   Major|\n",
      "|      Ms|\n",
      "+--------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#displaying the intials for the names\n",
    "STD_df.select(\"Initial\").distinct().show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some intials are mispelled like mlle and mme are related to miss. so I have replaced the misspelled intials with the correct ones. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+\n",
      "|Initial|\n",
      "+-------+\n",
      "|   Miss|\n",
      "|  Other|\n",
      "| Master|\n",
      "|     Mr|\n",
      "|    Mrs|\n",
      "+-------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Replacing the misspelled Intials\n",
    "STD_df = STD_df.replace(['Mlle','Mme', 'Ms', 'Dr','Major','Lady','Countess','Jonkheer','Col','Rev','Capt','Sir','Don'],\n",
    "               ['Miss','Miss','Miss','Mr','Mr',  'Mrs',  'Mrs',  'Other',  'Other','Other','Mr','Mr','Mr'])\n",
    "STD_df.select(\"Initial\").distinct().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(Initial='Miss', avg(Age)=21.86),\n",
       " Row(Initial='Other', avg(Age)=45.888888888888886),\n",
       " Row(Initial='Master', avg(Age)=4.574166666666667),\n",
       " Row(Initial='Mr', avg(Age)=32.73960880195599),\n",
       " Row(Initial='Mrs', avg(Age)=35.981818181818184)]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Now calculating the average age of the passengers depending on the Initials\n",
    "STD_df.groupby('Initial').avg('Age').collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Now lets assign the missing values in the columns based on the average age of the Initials\n",
    "STD_df = STD_df.withColumn(\"Age\",when((STD_df[\"Initial\"] == \"Miss\") & (STD_df[\"Age\"].isNull()), 22).otherwise(STD_df[\"Age\"]))\n",
    "STD_df = STD_df.withColumn(\"Age\",when((STD_df[\"Initial\"] == \"Other\") & (STD_df[\"Age\"].isNull()), 46).otherwise(STD_df[\"Age\"]))\n",
    "STD_df = STD_df.withColumn(\"Age\",when((STD_df[\"Initial\"] == \"Master\") & (STD_df[\"Age\"].isNull()), 5).otherwise(STD_df[\"Age\"]))\n",
    "STD_df = STD_df.withColumn(\"Age\",when((STD_df[\"Initial\"] == \"Mr\") & (STD_df[\"Age\"].isNull()), 33).otherwise(STD_df[\"Age\"]))\n",
    "STD_df = STD_df.withColumn(\"Age\",when((STD_df[\"Initial\"] == \"Mrs\") & (STD_df[\"Age\"].isNull()), 36).otherwise(STD_df[\"Age\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+\n",
      "|Initial|\n",
      "+-------+\n",
      "|     Mr|\n",
      "|     Mr|\n",
      "|     Mr|\n",
      "+-------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "STD_df.filter(STD_df.Age==46).select(\"Initial\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+\n",
      "| Age|\n",
      "+----+\n",
      "|22.0|\n",
      "|38.0|\n",
      "|26.0|\n",
      "|35.0|\n",
      "|35.0|\n",
      "+----+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "STD_df.select(\"Age\").show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+-----+\n",
      "|Embarked|count|\n",
      "+--------+-----+\n",
      "|       Q|   77|\n",
      "|    null|    2|\n",
      "|       C|  168|\n",
      "|       S|  644|\n",
      "+--------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Checking the null values in the \n",
    "STD_df.groupBy(\"Embarked\").count().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- PassengerId: integer (nullable = true)\n",
      " |-- Survived: integer (nullable = true)\n",
      " |-- Pclass: integer (nullable = true)\n",
      " |-- Name: string (nullable = true)\n",
      " |-- Sex: string (nullable = true)\n",
      " |-- Age: double (nullable = true)\n",
      " |-- SibSp: integer (nullable = true)\n",
      " |-- Parch: integer (nullable = true)\n",
      " |-- Ticket: string (nullable = true)\n",
      " |-- Fare: double (nullable = true)\n",
      " |-- Embarked: string (nullable = false)\n",
      " |-- Initial: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Filling the null values in the Embarked column\n",
    "STD_df = STD_df.na.fill({\"Embarked\" : 'S'})\n",
    "#Dropping the cabin column as it is not an important feature which effects the model and has lot of null values\n",
    "STD_df = STD_df.drop(\"Cabin\")\n",
    "STD_df.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will build and evaluate a new function called \"Family size\" and \"Alone.\" This functionality is combined sum of Parch(parents / children) and SibSp(siblings / spouses). This provides us a combined data so we can test if survival rate has anything to do with passenger family size."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+-----+\n",
      "|Family_Size|count|\n",
      "+-----------+-----+\n",
      "|          1|  161|\n",
      "|          6|   12|\n",
      "|          3|   29|\n",
      "|          5|   22|\n",
      "|          4|   15|\n",
      "|          7|    6|\n",
      "|         10|    7|\n",
      "|          2|  102|\n",
      "|          0|  537|\n",
      "+-----------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#creating family_size column\n",
    "STD_df = STD_df.withColumn(\"Family_Size\",col('SibSp')+col('Parch'))\n",
    "STD_df.groupBy(\"Family_Size\").count().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['PassengerId',\n",
       " 'Survived',\n",
       " 'Pclass',\n",
       " 'Name',\n",
       " 'Sex',\n",
       " 'Age',\n",
       " 'SibSp',\n",
       " 'Parch',\n",
       " 'Ticket',\n",
       " 'Fare',\n",
       " 'Embarked',\n",
       " 'Initial',\n",
       " 'Family_Size',\n",
       " 'Alone']"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#creating the Alone column and assign some values 0 means alone and 1 means family size\n",
    "STD_df = STD_df.withColumn('Alone',lit(0))\n",
    "STD_df = STD_df.withColumn(\"Alone\",when(STD_df[\"Family_Size\"] == 0, 1).otherwise(STD_df[\"Alone\"]))\n",
    "STD_df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+--------+------+--------------------+------+----+-----+-----+----------------+-------+--------+-------+-----------+-----+---------+--------------+-------------+\n",
      "|PassengerId|Survived|Pclass|                Name|   Sex| Age|SibSp|Parch|          Ticket|   Fare|Embarked|Initial|Family_Size|Alone|Sex_index|Embarked_index|Initial_index|\n",
      "+-----------+--------+------+--------------------+------+----+-----+-----+----------------+-------+--------+-------+-----------+-----+---------+--------------+-------------+\n",
      "|          1|       0|     3|Braund, Mr. Owen ...|  male|22.0|    1|    0|       A/5 21171|   7.25|       S|     Mr|          1|    0|      0.0|           0.0|          0.0|\n",
      "|          2|       1|     1|Cumings, Mrs. Joh...|female|38.0|    1|    0|        PC 17599|71.2833|       C|    Mrs|          1|    0|      1.0|           1.0|          2.0|\n",
      "|          3|       1|     3|Heikkinen, Miss. ...|female|26.0|    0|    0|STON/O2. 3101282|  7.925|       S|   Miss|          0|    1|      1.0|           0.0|          1.0|\n",
      "|          4|       1|     1|Futrelle, Mrs. Ja...|female|35.0|    1|    0|          113803|   53.1|       S|    Mrs|          1|    0|      1.0|           0.0|          2.0|\n",
      "|          5|       0|     3|Allen, Mr. Willia...|  male|35.0|    0|    0|          373450|   8.05|       S|     Mr|          0|    1|      0.0|           0.0|          0.0|\n",
      "+-----------+--------+------+--------------------+------+----+-----+-----+----------------+-------+--------+-------+-----------+-----+---------+--------------+-------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# converting Sex, Embarked & Initial columns from string to number using StringIndexer\n",
    "indexers = [StringIndexer(inputCol=column, outputCol=column+\"_index\").fit(STD_df) for column in [\"Sex\",\"Embarked\",\"Initial\"]]\n",
    "pipeline = Pipeline(stages=indexers)\n",
    "STD_df = pipeline.fit(STD_df).transform(STD_df)\n",
    "STD_df.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+------+----+-----+-----+-------+-----------+-----+---------+--------------+-------------+\n",
      "|Survived|Pclass| Age|SibSp|Parch|   Fare|Family_Size|Alone|Sex_index|Embarked_index|Initial_index|\n",
      "+--------+------+----+-----+-----+-------+-----------+-----+---------+--------------+-------------+\n",
      "|       0|     3|22.0|    1|    0|   7.25|          1|    0|      0.0|           0.0|          0.0|\n",
      "|       1|     1|38.0|    1|    0|71.2833|          1|    0|      1.0|           1.0|          2.0|\n",
      "|       1|     3|26.0|    0|    0|  7.925|          0|    1|      1.0|           0.0|          1.0|\n",
      "|       1|     1|35.0|    1|    0|   53.1|          1|    0|      1.0|           0.0|          2.0|\n",
      "|       0|     3|35.0|    0|    0|   8.05|          0|    1|      0.0|           0.0|          0.0|\n",
      "+--------+------+----+-----+-----+-------+-----------+-----+---------+--------------+-------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#dropping columns which are not required\n",
    "STD_df = STD_df.drop(\"PassengerId\",\"Name\",\"Ticket\",\"Cabin\",\"Embarked\",\"Sex\",\"Initial\")\n",
    "STD_df.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+------+----+-----+-----+-------+-----------+-----+---------+--------------+-------------+--------------------+\n",
      "|Survived|Pclass| Age|SibSp|Parch|   Fare|Family_Size|Alone|Sex_index|Embarked_index|Initial_index|            features|\n",
      "+--------+------+----+-----+-----+-------+-----------+-----+---------+--------------+-------------+--------------------+\n",
      "|       0|     3|22.0|    1|    0|   7.25|          1|    0|      0.0|           0.0|          0.0|(10,[0,1,2,4,5],[...|\n",
      "|       1|     1|38.0|    1|    0|71.2833|          1|    0|      1.0|           1.0|          2.0|[1.0,38.0,1.0,0.0...|\n",
      "|       1|     3|26.0|    0|    0|  7.925|          0|    1|      1.0|           0.0|          1.0|[3.0,26.0,0.0,0.0...|\n",
      "|       1|     1|35.0|    1|    0|   53.1|          1|    0|      1.0|           0.0|          2.0|[1.0,35.0,1.0,0.0...|\n",
      "|       0|     3|35.0|    0|    0|   8.05|          0|    1|      0.0|           0.0|          0.0|(10,[0,1,4,6],[3....|\n",
      "+--------+------+----+-----+-----+-------+-----------+-----+---------+--------------+-------------+--------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Converting the features into one single vector\n",
    "feature = VectorAssembler(inputCols=STD_df.columns[1:],outputCol=\"features\")\n",
    "feature_vector= feature.transform(STD_df)\n",
    "feature_vector.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modelling "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now spliting the training and testing set by utilizing 80% of the train data\n",
    "(trainingData, testData) = feature_vector.randomSplit([0.8, 0.2],seed = 11)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+--------+--------------------+\n",
      "|prediction|Survived|            features|\n",
      "+----------+--------+--------------------+\n",
      "|       0.0|       0|[1.0,19.0,3.0,2.0...|\n",
      "|       1.0|       0|[1.0,27.0,0.0,2.0...|\n",
      "|       0.0|       0|(10,[0,1,4,6],[1....|\n",
      "|       0.0|       0|[1.0,28.0,1.0,0.0...|\n",
      "|       0.0|       0|(10,[0,1,4,6],[1....|\n",
      "|       0.0|       0|(10,[0,1,4,6,8],[...|\n",
      "|       0.0|       0|(10,[0,1,3,4,5],[...|\n",
      "|       0.0|       0|(10,[0,1,6],[1.0,...|\n",
      "|       0.0|       0|(10,[0,1,4,6,8],[...|\n",
      "|       0.0|       0|(10,[0,1,2,4,5],[...|\n",
      "|       0.0|       0|[1.0,51.0,0.0,1.0...|\n",
      "|       0.0|       0|(10,[0,1,4,6,8],[...|\n",
      "|       0.0|       0|(10,[0,1,4,6,8],[...|\n",
      "|       0.0|       0|(10,[0,1,4,6],[2....|\n",
      "|       0.0|       0|(10,[0,1,4,6],[2....|\n",
      "|       0.0|       0|(10,[0,1,4,6],[2....|\n",
      "|       0.0|       0|(10,[0,1,2,4,5],[...|\n",
      "|       0.0|       0|(10,[0,1,2,4,5],[...|\n",
      "|       0.0|       0|(10,[0,1,2,4,5],[...|\n",
      "|       0.0|       0|(10,[0,1,4,6],[2....|\n",
      "+----------+--------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.classification import RandomForestClassifier\n",
    "rf = RandomForestClassifier(labelCol=\"Survived\", featuresCol=\"features\")\n",
    "rf_model = rf.fit(trainingData)\n",
    "rf_prediction = rf_model.transform(testData)\n",
    "rf_prediction.select(\"prediction\", \"Survived\", \"features\").show()\n",
    "evaluator = MulticlassClassificationEvaluator(labelCol=\"Survived\", predictionCol=\"prediction\", metricName=\"accuracy\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Performance Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of RandomForestClassifier is = 0.836257\n",
      "Test Error of RandomForestClassifier  = 0.163743 \n"
     ]
    }
   ],
   "source": [
    "#Checking the accuracy of the random forest calssifier\n",
    "rf_accuracy = evaluator.evaluate(rf_prediction)\n",
    "print(\"Accuracy of RandomForestClassifier is = %g\"% (rf_accuracy))\n",
    "print(\"Test Error of RandomForestClassifier  = %g \" % (1.00 - rf_accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Area Under ROC: 1.0\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.evaluation import BinaryClassificationEvaluator\n",
    "evaluator = BinaryClassificationEvaluator(labelCol=\"prediction\")\n",
    "print(\"Test Area Under ROC: \" + str(evaluator.evaluate(rf_prediction, \n",
    "                                    {evaluator.metricName: \"areaUnderROC\"})))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
